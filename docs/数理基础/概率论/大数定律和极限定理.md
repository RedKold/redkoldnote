---
share: "true"
---

# 大数定律 和 中心极限定理
大数定律的研究是对我们直观印象的深化理解。
- 频率具有稳定性
- 平均值具有稳定性
基于这个考虑，我们有数学语言表达

Def1：设$X_{n}(n=1,2,3\dots)$是一个r.v序列，若存在r.v.$X$，使得对任意的正数$\mathbb{\epsilon}$， 恒有 $\lim_{ n \to \infty }P\{{|X_{n}-X|\geq\epsilon}\}=0$
**称为 随机变量序列$\{X_{n}\}$依概率收敛于随机变量$X$**
记作
$$\begin{align}
&\lim_{ n \to \infty } X_{n}=X(P)\\
&X_{n}{\overset{P}{\to}}X
\end{align}
$$

## 1. 切比雪夫大数定律(Chebyshev)

设$X_{1},X_{2},\dots,X_{n},\dots，$是由**相互独立的**$r.v$所构成的序列，$E(X_{k})=\mu_{k}$并且它们的方差有**公共的上界** $\mathrm{D}(X_{k})\leq C\;(k=1,2\dots)$

则对$\forall\epsilon>0$，都有
$$
\lim_{ n \to \infty } P\left\{\left\lvert  \frac{1}{n}\sum_{k=1}^n X_{k}-\frac{1}{n}\sum_{k=1}^n\mu_{k}\right\rvert<\epsilon\right\}=1
$$
有**切比雪夫不等式**
$$
P\left\{\lvert X-\mu \rvert\geq\epsilon\right\}\leq \frac{\sigma^2}{\epsilon^2}
$$
或
$$
P\left\{\lvert X-\mu\rvert<\epsilon\right\}\geq 1-\frac{\sigma^2}{\epsilon^2}
$$

## 伯努利大数定律
设 $n_A$ 是 $n$ 次独立重复试验中 $A$ 发生的次数，$p$ 是事件 $A$ 在每次试验中发生的概率，则 $\forall\epsilon>0$, 有
$$
\lim_{ n \to \infty }P\left\{\lvert \frac{n_A}{n}-p\rvert<\epsilon \right\}=1
$$
即
- 事件$A$发生的频率 $\frac{n_{A}}{n}$依概率收敛到事件$A$发生的概率$p$，这就以严格的数学形式表达了频率的稳定性。
- 这就是说当$n$相当大的时候，事件$A$发生的概率和频率有较大差别的可能性很小，因而在实际中可以用频率来代替概率

> [!Tip] 可以用切比雪夫不等式证明

## 辛钦大数定律
设 r.v. $X_{1},X_{2},\dots,X_{n},\dots$ **相互独立，服从同一分布**，且具数学期望 $\mathbb{E}(X_{k})=\mu,\;(k=1,2,\dots)$，则对 $\forall\varepsilon>0$，
$$
\lim_{ n \to \infty } \left\{\lvert \frac{1}{n}\sum_{k=1}^nX_{k}-\mu\rvert<\varepsilon\right\}=1
$$
这告诉我们样本均值可以代替整体均值。

## 独立同分布的中心极限定理

设r.v. $X_{k}\;(k=1,2,\dots)$相互独立，服从同一分布$(i.i.d)$且具有有限的数学期望和方差：$E(X_{k}=\mu)$,$D(X_{k})=\sigma^2\neq{0},\;k=1,2\dots$则r.v
$$
\begin{align}
Y_{n}=&\frac{\sum_{k=1}^nX_{k}-E\left( \sum_{k=1}^nX_{k} \right)}{\sqrt{ D\left( \sum_{k=1}^n X_{k}\right) }} \\
=&\frac{\sum_{k=1}^n X_{k}-n\mu}{\sqrt{ n }\sigma}
\end{align}
$$
的分布函数$F_n$对于$\forall \,x$
$$
\lim_{ n \to \infty } F_{n}(x)=\lim_{ n \to \infty } P\left\{Y_{n}\leq x\right\}=\int_{-\infty}^{x} \frac{{1}}{\sqrt{ 2\pi }}\exp\left( -\frac{t^2}{2} \right) \, dt 
$$
即r.v序列$Y_{n}=\frac{\sum_{k=1}^n X_{k}-n\mu}{\sqrt{ n }\sigma}\overset{L}{\to}N(0,1)$

中心极限定理实际上讲述了$\overline{X}$ 具有**近似正态性**

总结大数定律
- 大数定律
	- **定义**：大数定律说明了在进行**大量独立同分布**的随机试验时，样本均值将**趋近于总体均值**。换句话说，随着样本数量的增加，观测值的平均值会越来越接近期望值。
	- **意义**：大数定律保证了长期来看，随机现象的平均结果是稳定的。例如，投掷足够多次硬币，正反面的比例将趋近于50%。
- 中心极限定理
	- **定义**：中心极限定理表明，对于一组**独立同分布**的随机变量，其和或均值在样本数量趋近于无穷大时，其分布将趋近于正态分布，无论这些随机变量的原始分布是什么。
	- **意义**：中心极限定理解释了为什么正态分布在自然和社会科学中如此普遍存在，即使单个现象不是正态分布，但它们的累加结果却趋近于正态分布。这使得正态分布成为许多统计分析方法的基础。

## 棣莫佛-拉普拉斯定理
设 r.v.$X_{n}(n=1,2,3,\dots)$ 服从**二项分布** $b(n,p)$，$i.i.d.$ 对于 $\forall x$，恒有
$$
\begin{gather*}
\lim_{ n \to \infty } P\left\{ \frac{{X_{n}-np}}{\sqrt{ np(1-p) }}\leq x \right\}=\int_{-\infty}^{x} {\frac{1}{\sqrt{ 2\pi }}e^{ -x^{2}/2 }} \;dt
\end{gather*}
$$ 当 $n$ 较大的时候，我们可以用正态分布的数值表来近似计算二项分布的概率。

## 林德贝格中心极限定理
